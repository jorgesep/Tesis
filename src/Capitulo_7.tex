\chapter{Conclusiones}\label{chap:conclusiones}

%Este trabajo de tesis se propuso como objetivo principal implementar un sistema de software, que permitiese en una primera parte la incorporación de algoritmos de sustracción de imágenes de fondo, empleados en el campo de investigación de visión por computador. Y en una segunda parte el desarrollo de una herramienta de evaluación de desempeño, independiente de los algoritmos incorporados en este sistema, que incluyera un conjunto de métricas empleadas comúnmente en visión por computador (u otras disciplinas de maquina de aprendizaje computacional, reconocimiento de patrones, sistemas de recuperación de información, etc) y funcionase como un sistema de evaluación independiente, con la finalidad de evaluar sólo mascaras de imágenes resultantes sin necesidad de conocer la base de funcionamiento de algún algoritmo en evaluación. El proyectoTodo este 

%para finalmente terminar nuevamente vinculados en el resultado final de este proyecto de tesis

Este trabajo de tesis fue desarrollado en base a tres dimensiones. En la primera parte se propone el objetivo principal de implementar un sistema de software, que permitiese la incorporación de algoritmos de sustracción de imágenes de fondo, empleados en el campo de investigación de visión por computador. En una segunda parte se proyecta el desarrollo de una herramienta de evaluación de desempeño, independiente de los algoritmos incorporados en este sistema, que incluyera un conjunto de métricas utilizadas comúnmente en visión por computador (u otras disciplinas de maquina de aprendizaje computacional, reconocimiento de patrones, sistemas de recuperación de información, etc) y además funcionase como un sistema de evaluación autónomo, con la finalidad de evaluar sólo mascaras de imágenes resultantes sin necesidad de conocer la lógica de funcionamiento del algoritmo en evaluación. Y un último aspecto se relaciona con el conjunto de datos MuHAVI, que actúa como el componente de evaluación del desarrollo de este proyecto de tesis, en base a este conjunto de datos surgen desafíos que se fueron superando durante las distintas etapas de trabajo. 

Una de las salidas de este proyecto corresponde al sistema de software, que incorpora un grupo de algoritmos basados principalmente en mixtura de componentes Gaussiano, orientados a realizar sustracción de imágenes de fondo, procedimiento también denominado por sus nombres en ingles, \textit{Background Subtraction} o \textit{Foreground and Background separation}. La implementación del software utiliza como sustento el conjunto de biblioteca de clases C++, disponibles en la plataforma abierta de visión por computador \textit{OpenCV} y desarrollado en una plataforma \textit{Linux} de 32 bits. El sistema final corresponde a un conjunto de bibliotecas C++, archivos xml de configuración y un grupo de programas de computación que permiten la ejecución y utilización de estos algoritmos de visión por computador en cualquier secuencia de video disponible.  Este software tiene la flexibilidad de incorporar nuevos algoritmos, y requiere para esto las clases y métodos empaquetadas en una biblioteca tipo \textit{Linux}. Sin embargo, este último requerimiento crea una restricción importante, y deja fuera por incompatibilidad de sistema operativos, una buena parte de antiguos y nuevos prototipos que la comunidad de investigación en este campo está desarrollando.

El segundo producto del proyecto se manifiesta como respuesta a la inquietud de una búsqueda de evaluación de los algoritmos incorporados en el sistema anterior. Interesaba saber de manera imparcial el rendimiento de los algoritmos utilizados en un conjunto de datos como MuHAVI. Se hace una investigación y se evidencia que existen bastantes métricas de evaluación de desempeño, y la mayoría de ellas basadas en discrepancia, es decir, comparación de una imagen resultado (mascara) con su referencia. En este proyecto se implementa una herramienta que incluye varias de estas métricas, cada una de ellas destaca en forma individual alguna característica de un algoritmo, pero en su conjunto entregan una visión más completa de desempeño. El software es un programa ejecutable que admite dos entradas, las mascaras binarias (imágenes de siluetas) y las referencias (\textit{ground-truth}), el resultado es un archivo de texto con un resumen por imagen de las mediciones realizadas por el programa. Las métricas integradas más importantes, se fundamentan en el resultado de clasificación a nivel de pixel. El programa identifica si un pixel ha sido bien seleccionado y a partir de esa comparación puede determinar el nivel de clasificación de un algoritmo. Identifica el nivel de `\textit{especificidad}' y `\textit{sensitividad}', es decir, realiza una medición de la proporción de positivos y negativos correctamente clasificados. Estas dos mediciones permiten generar un número distinto de métricas orientadas a responder diversas preguntas en la evaluación de desempeño. En el transcurso de la experimentación se logra determinar que el coeficiente de correlación \textit{MCC} y \textit{F-Measure}, en este proyecto, se pueden considerar mediciones de desempeño equivalentes. Lo mismo sucede con las métricas de \textit{PSNR} y \textit{MSSIM} las dos producen similares resultados, por lo que no se requiere la utilización de ambas. Una de las mediciones más relevantes encontradas durante este trabajo, es la métrica \textit{D-Score}, la cual entrega una medición que descarta los falsos positivo lejanos y pondera mayormente los pixeles falsos positivos cercanos a la forma del objeto (siluetas en este  proyecto) que se intenta reconocer, de esta manera, se corrobora que esta métrica entrega una buena indicación, de la factibilidad de reconocer la forma de la silueta en procesos posteriores. El mayor inconveniente de esta métrica es el extensivo procesamiento computacional, realiza extensos cálculos de distancia que condiciona su uso a la potencia del equipamiento usado. De todas manera esta restricción computacional en un futuro cercano no será inconveniente, por el vertiginoso avance en potencia de los equipos de computación.

Una tercera parte de este proyecto, es el análisis de los resultados de la experimentación. Todas las conclusiones de desempeño de los algoritmos, se basan en los análisis de mediciones globales promedios obtenidas durante la experimentación. Una medición es el promedio general de resultados parciales de ejecuciones realizadas sobre cada secuencia del conjunto de datos MuHAVI. El promedio de mediciones por algoritmo es un indicador global, que oculta el desempeño particular de los algoritmos evaluados sobre alguna secuencia específica. MuHAVI expone desafíos adicionales, fuera del problema básico de reconocer una acción humana, que puede interesar observar en la evaluación final y se ocultan en las mediciones globales resultantes. El tipo iluminación usado en la construcción de este conjunto de datos genera problemas que pueden resultar difíciles de resolver por los algoritmos e incide en el deterioro de su desempeño final; estos son figuras fantasmas (sombras de las actores proyectadas en el escenario por más tiempo de lo necesario), cambios pequeños en la iluminación global que puede confundir al algoritmo e invertir el reconocimiento de una figura del fondo (o viceversa), y las sombras de los actores proyectadas en el escenario que se confunden como una extensión de la figura humana. Sin embargo, el promedio general de las mediciones en su conjunto construye un buen indicador de desempeño de los algoritmos. La etapa de experimentación por ejemplo ha determinado, contrastando curvas de operaciones y comparando las mediciones de las métricas desempeño, que el algoritmo \textit{SAGMM} presenta  rendimiento mejor con respecto a los otros algoritmos, y esto se confirma visualmente al observar algunas imágenes de resultados tomadas al azar, que ratifican la calidad de la silueta con respecto a los algoritmo similares.

Con respecto al desempeño individual de los algoritmos escogidos. Se ha demostrado por ejemplo que el algoritmo de Zezhi Chen \cite{chen_vehicle_2012} denominado \textit{SAGMM} es una mejora del algoritmo de \textit{Zivkovic y Heijden} \cite{zivkovic_efficient_2006} denominado \textit{MOG2} (\textit{Mixture Of Gaussians}). \textit{SAGMM} agrega esencialmente dos nuevos componentes al algoritmo original. Incorpora, en la etapa previa de procesamiento, un filtro de procesamiento temporal (cadena continua de cuadros dentro de una secuencia) y espacial (filtro gaussiano entre pixeles de un vecindario) que favorece la estabilidad a nivel de imagen y posibilita mejor discriminación de componentes gaussianos durante el procesamiento del algoritmo. Asimismo incluye un factor de iluminación global con el propósito de compensar cambios bruscos de luminosidad. Estos dos nuevos elementos se evidencian en el mejor desempeño de éste sobre \textit{MOG2}. La implementación de este algoritmo, junto con MOG2,  forma la base del sistema desarrollado para este proyecto. A pesar, que los algoritmos UCV \textit{Staircase} y \textit{Linear} presentan un desempeño desmejorado con respecto a los otros basados en mixtura de componentes Gaussianas, estos algoritmos están orientados a ser incorporados en sistemas embebidos basados en micro-controladores, en consecuencia abordan restricciones y complejidades que constituyen las fortalezas y ventajas de \textit{UCV}, que los otros algoritmos no consideran dentro de sus diseños. Esto último revela una carencia de este trabajo, y es dejar fuera las métricas de evaluación de los tiempos de ejecución, o la medición de la cantidad de recursos computacionales (el uso de memoria o carga de CPU) requeridos por un algoritmo. Estas mediciones agregarían una nueva dimensión a la evaluación global y van en el camino de destacar particularidades que pueden tener los algoritmos y no se reflejan en el contexto global. 

MuHAVI por su parte es un conjunto de datos que proporciona con muchas vistas (disposición de cámaras en diferentes ángulos) de la misma acción (o del conjunto de acciones), eso conlleva resultados con diferentes varianzas de las mediciones globales. La última parte de la experimentación intenta identificar estas varianzas en el resultado global de la curva de operaciones, al obtener los intervalos de confianza del resultado promedio, y generar un rango (o banda) de valores con una probabilidad del 95\% donde se localiza el resultado. Pero se necesita un análisis estadístico más extenso de los resultados, el estudio de los intervalos de confianza sólo considera 20 muestras globales generales por algoritmo (promedio de 5 secuencias, con 2 actores y 2 cámaras) y considera una distribución de muestreo normal de la media de las muestras, para hacer inferencia estadística de la curva de operaciones. Este mismo estudio se podría hacer considerando por ejemplo una distribución binomial por la naturaleza binaria de las muestras (pixel de una imagen en dos estados) o bien una distribución t (\textit{Student}) por el tamaño pequeño de las muestras. Igualmente, se asumió una distribución normal subyacente al estimar la media estadística del resultado de una secuencia como un indicador global (promedio de la tasa de verdadero y falsos positivos). El conjunto de valores que resultan del procesamiento de una secuencia (por algoritmo) constituye un cluster de valores que no necesariamente se pueden estimar como una distribución normal (o binormal con ambos valores), esto por consiguiente deja abierta la inquietud de considerar el promedio general como un buen indicador global de rendimiento. De esta forma se podría buscar otra estadística que mejor identifique el respuesta de un algoritmo, por ejemplo usar la mediana en vez del promedio. Un trabajo futuro debiera intentar estimar la distribución subyacente de los resultados de una secuencia; estimar los sesgo de la distribución, modelar como una distribución binomial, o usar un modelo no-paramétrico para estimar las distribuciones del resultado de procesamiento de las secuencias. Por otra parte, no queda claro donde surge la variabilidad de los resultados, se puede relacionar esta variabilidad con la respuesta de los algoritmos a los cambios sutiles de iluminación en MuHAVI, afecta el color de la ropa de los actores (ropa oscura en un escenario con poca iluminación) en el resultado global.

Finalmente como trabajo futuro, queda pendiente incorporar un nuevo módulo en el sistema de software que implemente algún algoritmo de reconocimiento de acciones. Con el propósito de corroborar los resultados obtenidos en este trabajo de tesis, verificar que los algoritmos evaluados con buen desempeño entregan una buena base para realizar reconocimiento de acciones. Esto abre nuevas preguntas, las métricas para evaluar los algoritmos estudiados sirven igualmente para evaluar los algoritmos de detección de acciones, se necesitaría un tipo diferente de métricas, el concepto de discrepancia como método de evaluación sigue siendo válido en detección de acciones. En la misma línea, pero por el lado de la implementación de software, es necesario, que todos los algoritmos que se implementen a futuro usen alguna técnica de paralelismo, como cluster con tarjetas GPU, esto reduciría sin duda enormemente los tiempos de experimentación, pero introduce los desafíos técnicos de implementar estos algoritmos en kernels GPU para la ejecución.


%- Quedan fuera los tiempos de ejecución, incorporar GPU
%- Box, zona de interes
%
%
%
%
%De esta forma se podría encontrar una estadística que mejor identifique la respuesta de una algoritmo, por ejemplo usar mediana en vez del promedio, o reconocer el sesgo de la distribución estadística de respuesta. 
%
%. No queda claro en este trabajo de donde surge la variabilidad de las respuestas, o porque las respuestas en las curvas de operaciones se alejan de la curva promedio. SE puede relacionar el factor de iluminación de MuHAVI con la variabilidad que se encuentra en el resultado de las distintas secuencias. Afecta el color de la ropa de los actores en los resultados  el valque el algoritmo  el problema de las diferentes varianzas en el  
%
%
%
%   distribución o  
%
%deja la inquietud queda abierto  y en consecuencia tampoco se podría considerar la estadística . Una alternativa de este trabajo, por ejemplo, puede consistir en utilizar la mediana en vez de la media, un estudio más detallado resultado de cadaLa salida de cada secuencia (por algoritmo) es en si mismo de cada secuencia es en si mismo un cluster . , pero  nivel de secuencia se toma como indicador global la estadística de la media Por otra parte, el estudio a nivel de secuencia, se considera la media estadística como un indicador global del resultado estadístico (con m) un número el número estadístico que se obtiene como indicador global es la media  parte la estadística que se obtien
%
%Las curvas ROC es una herramienta muy utilizada en el campo del diagnóstico médico, las cuales se han llevado para el análisis de clasificación binaria y estas mismas herramientas se sus desde ese campo se han desarrollo los pero  Se requiere, por ejemplo, identificar el tipo de distribución estadística que está parte requiere más profundización. Por ejemplo, se podría identificar el tipo de distribución estadística que tienen por secuencia los resultados de verdadero y falsos positivos. 
%La continuación de este trabajo 
%
%fue el tiempo de toma una ejecución completa de una secuencia, o la cantidad de recursos computacionales que se necesitan para utilizar estos algoritmos. En estos dos aspectos, \textit{UCV} tiene una ventaja competitiva.   en este ambiente Se incluye también otros dos algoritmos basados en mistura de Gaussianas, pero orientados a sistemas embebidos tipo micro-controladores. Finalmente el desarrollo de esta etapa microncontroladores También incluye dos algoritmos que Este algoritmo se incorpora en el sistema base de este proyecto, la base del sistema implementado. 
%
%Sin embargo, a pesar del comentario anterior, es importante reconocer que el promedio global nos da un buen indicador del desempeño de los algoritmos. En la etapa de experimentación se ha determinado que el algoritmo \textit{SAGMM} ha tenido un bueno desempeño, las cifras globales de los resultados indican que este algoritmo tiene un rendimiento mejor que los demas evaluados. Esto se comprueba 
%
%
%  de los n el reconocimiento de colores y generar zonas de siluetas los colores de iluminación que provoca confunden lprovocan en ciertas partes del escenario  la secuencia tiempo después que el actor  El problema de la iluminación  resulta interesante evaluar el comportamiento de los algoritmos. Por ejemplo, un par de problemas en varias de sus secuencias    
%
%
%
%  parciales viene  se basan sobre análisis se basan sobre realizados corresponden a mediciones globales de desempeño, es decir, por cada una de las ejecuciones realizadas sobre las secuencias del conjunto de datos MuHAVI, se obtuvo un promedio de mediciones definidas en la herramienta de software, posteriormente, una vez que se fueron realizadas todas las ejecuciones del algoritmo sobre las secuencias, se obtuvo un promedio general con los promedios de todas las secuencias. 
%Este promedio de métricas de desempeño por algoritmo es en un indicador global, que puede ocultar muchos de los desafíos particulares que tienen las secuencias y no dice mucho como el algoritmo que está en evaluación lo resuelve. Por ejemplo varias secuencias de MuHAVI presentan problemas que se denominan fantasmas, es decir queda proyectada la sombra del actor más después que ésta ha dejado el escenario. Un algoritmo que no maneja bien este problema reporta un aumento en su cantidad de falsos positivos en esa secuencia, pero será atenuada por el resultado de las otras secuencias. Lo mismo sucede con los cambios bruscos de iluminación, es muy difícil, reconocer en términos globales el comportamiento de una algoritmo frente estos problemas mencionados, y que MuHAVI los contiene como una característica propia. 
%
%
%
%

%  , pero  particularidades de las secuencias y el la herramienta de software una de las métricas, para finalmente promediar esos resultados promedios por secuencia y así obtener un promedio general hizo un promedio de las métricas se seleccionó un algoritmo del sistema  un algoritmo 
%
% para que posteriormente sea segmen. Este ha resultado ser un buen indicador mediciones de de de la clasificación se fundamentaLas métricas integradas consisten en mediciones de 
%
%El software desarrollado permite agregar  la biblioteca de clases de vision por computador C++  La primera parte, corresponde a una de las salidas de este proyecto. Este consiste de una sistema de software que se compone de una plataforma base la producto que este proyecto entrega al sistema implementado  que corresponde al sistema implementado, cEl sistema implementado consiste de un grupo de algoritmos basados en una mixtura de componentes gaussianos. , la base del programa  
%La implementación (migración desde Matlab) del algoritmo \textit{SAGMM} \cite{chen_vehicle_2012}, es parte de los objetivos específicos planteados al inicio. Se utiliza para este propósito el conjunto de clases y bibliotecas que dispone la plataforma de visión por computador \textit{OpenCV}. Gran parte de esta primera parte se deriva en entender el funcionamiento de los algoritmos basado en mixtura de componentes Gaussianos, y principalmente el trabajo propuesto por \textit{Zivkovic y Heijden} \cite{zivkovic_efficient_2006}. Esto debido que el algoritmo Zezhi Chen \cite{chen_vehicle_2012} denominado \textit{SAGMM}, propone dos mejoras del algoritmo de estos últimos autores mencionados y es denominado \textit{MOG2} (\textit{Mixture Of Gaussians}). Esencialmente el algoritmo \textit{SAGMM}  incorpora en una etapa previa un filtro de procesamiento temporal (cadena continua de cuadros dentro de una secuencia) y espacial (filtro gaussiano entre pixeles de un vecindario) que favorece la estabilidad de nivel de imagen y posibilita mejor discriminación de componentes gaussianos durante el procesamiento del algoritmo, y como el desarrollo de esta algoritmo surge en el campo de la vigilancia, agrega un factor iluminación global que compensa bruscos cambios de luminosidad. La implementación de este algoritmo, junto con MOG2,  forma la base del sistema desarrollado para este proyecto. Se incluye también otros dos algoritmos basados en mistura de Gaussianas, pero orientados a sistemas embebidos tipo micro-controladores. Finalmente el desarrollo de esta etapa microncontroladores También incluye dos algoritmos que Este algoritmo se incorpora en el sistema base de este proyecto, la base del sistema implementado 
%
%agrega un filtro de iluminaci. Una segunda procesamiento gaussiano)ees un filtro temporal y espacial que mejora la estabilidad de una imagen a nivel de pixel y mejora  de las secuencias de entrada el algoritmo se basa en este último   propuesto por  El algoritmo , de se utiliza para este efecto la plataforma de visión por computador \textit{OpenCV}, la cual ofrece muchas bilbioteca de clases en C++ utilizando par 
%Se requiere de un conjunto de datos con desafíos que emulen los aspectos de la vida diaria y real importantes. Se requiere de un conjunto de datos con desafíos reales para evaluar y mejorar los algoritmos desarrollar, para    Y una último aspecto que incTodo esto El proyectoTodo este 
%Desde el mundo de los algoritmos surgen ideas bla bla bla 
%
%Ambos sistemas de software (base de algoritmos, y herramienta de evaluacion de desempeño) fueron implementados y verificados con diferentes algoritmos. El primer tiempo del proyecto se inicio con la implementación del algoritmo SAGMM \cite{chen_vehicle_2012}  se inicio con el desarrollo del algoritmo  , y el tiempo de desarrollo necesito más tiempo del proyectado.    independientes fueron implementados, y tuvieron un tiempo de desarrollo fueron totalmente implementados 
%
%El desarrollo del sistema de software utiliza sistema de software está 
%La etapa de desarrollo requiere 
%
%Este proyecto nace de la necesidad de consolidar distintas métricas de evaluación que destacan alguna característica específica de los algoritmos, pero en la comunidad de investigación por computador no se utiliza un conjunto completo que evalúen diferentes dimensiones y entreguen una idea global de desempeño.
%
%que den idea global de desempeño el mundo existen diferentes métricas que  y se ocupa MuHAVI como conjunto de datos independientes  de manera de evaluar sólo las mascaras de imágenes resultantes sin necesidad de recurrir al algoritmo siendo evaluando que evaluase la salida resultado sin necesidad de requerir el algoritmo para realizar su experimentación. 
%
%
% evaluación. Sólo se requiere del salida . Se trata de  de un algoritmo para evaluar el resultado. l algoritmo que permitiese un sistema de evaluación independiente de  sistemas de recuperación de información, reconocimiento de patrones, y permitiese  . Pde estos algoritmos , como con un modulo que incluyera, o permitiese la fácil incorporación, de un conjunto de algoritmos muy empelados en el campo de la visión por computador, como los software de sustracción de imagenes de fondo y ademas otro módulo que implementara un conjunto de métricas de evaluación de desempeño de estos algoritmos. 
%
%
%realizara la eval agregar nuevos software en el futuro, un conjunto de algoritmos de muy utilizados en el campo de investigación de visión por computador en el futuro alque incorporara un modulo con  una bloque dos bloques principales. Una parte que permita  implementar un
%
%This dissertation addressed a framework for object detection, tracking and vehicle classification in an urban environment. A generalized active contour model for multi-channel and multi-phase colour image segmentation and an adaptive object-tracking algorithm have been proposed. By using level set methods, the mean shift tracking algorithm, a Chamfer distance transform (NCDT kernel) and sorted CSMs, objects can be detected and tracked. Their boundaries are not necessarily defined by a gradient or by very smooth boundaries, and hence classical active contour models are not applicable. The position of the initial curve can be anywhere in the image, and it does not necessarily surround the object to be detected. However, if the initial estimate is far from the true contour, it takes a long time to converge to the optimal solution. Several experiments have demonstrated the ability of the model to detect and track an object in movie sequences. Comparing the new method with the CVV method, the comparisons also show that the method proposed in the thesis is more accurate and robust in terms of image segmentation in the presence of symmetric and asymmetric noise.
